\documentclass[12pt]{diazessay}

\usepackage{bashful}
\usepackage{hyperref}

%----------------------------------------------------------------------------------------
%	Comment this out if you do not have `texcount` installed on your $PATH
%----------------------------------------------------------------------------------------
%\bash
%command -v texcount &> /dev/null && texcount -sum -1 csci-724-paper.tex
%\END

%Shorthand formatting commands
\newcommand{\F}[1]{$\quad$\texttt{#1}}
\newcommand{\A}{$\alpha$}
\newcommand{\B}{$\beta$}
\newcommand{\Bool   }{\texttt{Bool}}
\newcommand{\Nat    }{\texttt{Natural}}
\newcommand{\Integer}{\texttt{Integer}}
\newcommand{\Double }{\texttt{Double}}
\newcommand{\List   }{\texttt{List}}
\newcommand{\Type   }{\texttt{Type}}

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{\texttt{\huge{An analysis about effectiveness\\\vspace{-3mm}of structure-aware fuzzing} \\\vspace{-0.35cm} {\large A Hunter College CSCI-795 Project Proposal}\\\normalsize\url{https://github.com/recursion-ninja/Superion-YAML}}} % Title and subtitle

\author{\texttt{{\Huge Team:}\\\vspace*{-0.5em} 
		Sabina Bhuiyan \\\vspace*{-0.5em} 
		Kyoungwoo Lee \\\vspace*{-0.5em}
		Chuanyao Lin \\\vspace*{-0.25em}
		Alex Washburn}} % Author and institution

\date{\texttt{\today}} % Date, use \date{} for no date

\pagestyle{empty}

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Print the title section

\vspace{2cm}
\section*{Abstract}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%   NO citations in the abstract!   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

For our project, we propose exploring the efficiency of grey-box fuzzing programs with structured inputs compared to generically mutated random-like inputs.
The assessment will be adapted to test three major file formats: YAML, JSON, and Markdown.
Of all the ubiquitous file formats, these three are currently the most popular languages that are consumed as input by a wide array of programs and have enough CVEs that we can gauge the efficacy.

There are some state-of-the-art fuzzers that accentuate their effectiveness with structured input such as Gramatron, Superion, and Mayhem.
Excluding Mayhem, a commercial project for which we don't have access to its source code, we take two open-sourced projects; Gramatron and Superion as our extension target.
Grimoire is a fuzzer that, without structured inputs, can perform grammar awareness fuzzing by itself.

In the course of this project, we will extend the functionality of these two fuzzers and scrutinize the fuzzing capabilities of these extensions compared to other fuzzers like Grimoire against a corpus of CVEs of our three target file formats.
Our comparative metric will be both qualitative and quantitative; measuring coverage of CVEs and execution time to obtain coverage.

\clearpage

\section*{Introduction}

Fuzzing is a venerable application security testing technique developed in the late '80s\cite{Barton1988} and published in 1990\cite{Miller1990}.
Fuzzing tools generate input which is directed towards the program under test and detect if the input was accepted or caused unexpected behavior.
Unexpected behavior can take many forms, such as infinite loops, stack smashing, buffer overflows, arithmetic overflows or errors, and illegal program states.
Fuzzing tools themselves can take many forms\cite{ModelBasedFuzzing}\cite{GrammarBasedFuzzing}\cite{ProtocolBasedFuzzing} and modify program input in many ways.
Different fuzzing tools tend to specialize in a few related forms of input\cite{InputDiversity} manipulation.
There are three main classes of interaction between the fuzzer and the program under test, black-box\cite{takanen2018fuzzing}, grey-box, and white-box\cite{fuzzingsurvey}.
In a black-box scenario, the fuzzer has no knowledge of the program's internal structure and cannot use any program-specific information to direct its fuzzing efforts.
In a grey-box scenario, the fuzzer gleans information from its previous input to guide future inputs.
Lastly, in a white-box scenario, the fuzzer can utilize program analysis to inform its fuzzing inputs.

There are also two broad classes of inputs fuzzers generate; naive and structured\cite{fuzzingsurvey}.
Naive inputs do not provide any guarantees regarding its form.
Structured inputs, on the other hand, can be defined to always preserve desired structures within the inputs.

AFL\cite{AFL_page} is one of the best-known fuzzing tools. AFL relies on genetic algorithm techniques\cite{InputMutationAlgorithm} to mutate acceptable input into an input that triggers unexpected behavior.
Using the generic AFL approach, inputs would be mutated randomly, and an initially valid structured input would quickly become invalid.
The invalid input in this scenario, is not the one that introduces the vulnerability of the target system.
Random inputs just fail to run the major part of the target system, suspended by the type checkers or the input validators.
This is a longstanding problem in the art of fuzzing and is the subject of emerging research.
Generating consistently well-structured inputs\cite{structuredInput} via "grammar-aware" mutations is one such technique for addressing the problem of randomly mutated inputs.
AFL is a poster child for efficient, naive input fuzzing.

Unexpected behavior induced by a fuzzer often reveals security flaws in the program under test.
When security flaws affect publicly available software, professional ethics dictate the responsible disclosure of said security flaw and eventually publishing a Common Vulnerabilities and Exposures (CVEs) \cite{mell2002use} report detailing the security flaw's nature and available correction(s).
The utility of CVEs is two fold.
First, they provide a method for individuals to ensure that their software is patched for all known security flaws.
Second, it facilitates security researcher's ability to replicate the detailed security flaw.
We will be making use of this second role in our project.


\section*{Motivation}

We are aware of the topic "Going Beyond Coverage-Guided Fuzzing with Structured Fuzzing" by Jonathan Metzman in the Black Hat USA 2019\cite{blackhat2019}.
In the talk, the speaker presented structured fuzzing and how to improve the fuzzer by adding structure awareness to it. 
Therefore, we started our project with learning “What is Structured Fuzzing?”, and the concept of writing the well-structured inputs via "grammar-aware" mutations to improve the fuzzers we chose.

Superion\cite{superion} is an fairly recent open source fuzzing tool created by modifying and extending AFL to produce structured inputs released in 2018.
Superion currently generates valid JavaScript and XML inputs by taking a context free grammar and an input seed, then performing a series of "grammar-aware" mutations to create a sequence of validly structured inputs. The process is illustrated in the figure below.

\begin{center}
	\includegraphics[scale=0.4, trim={0 1cm 0 0}, clip]{superionfig.png}\\
	\textbf{Figure 1.} Grammar-aware input generation process of Superion
\end{center}
\vspace{3mm}

Based on the grammar, Superion parses each test input into an abstract syntax tree, an AST. Using ASTs, Superion introduces a grammar-aware trimming strategy that can effectively trim test inputs while keeping the input structure valid, then randomly chooses another input from AFL’s queue and also parses it into AST. A sub-tree of the target input can be replaced by another sub-tree, either from the target input itself or from a randomly chosen supplementary sample. Therefore, hundreds of new samples are generated and executed to find a new path in tested programs. The results of Superion show a great increase in fuzzing efficacy when targeting programs which expect structured input.

\clearpage

Gramatron\cite{srivastava2021gramatron} is a second, and even more recent, open source fuzzing tool designed to produce structured inputs.
Released in 2021, Gramatron was designed with new mutation algorithms to increase the speed at which defects are discovered.
It does this by reducing the number of mutation steps from the input seed to the trigger input, rather than simply optimizing the speed at which new inputs can be generated. There are two steps in which Gramatron modifies AFL++. First, in the preprocessing phase, the context-free grammar, CFG, is converted into Chomsky normal form, GNF/CNF, which is then turned into a finite state automata, FSA. This can be seen in the figure below.

\vspace{-1cm}
\begin{center}
	\includegraphics[scale=0.4, trim={0 3cm 0 0}, clip]{gramatronfig.png}
	\textbf{Figure 2.} Preprocessing phase of Gramatron
\end{center}
\vspace{6mm}

In the second step, the fuzzing phase, Gramatron performs the mutations with the FSAs and operators. Gramatron currently generates structured PHP and JavaScript as inputs.

Grimoire\cite{GRIMOIRE} is a structured input fuzzer which does not require an explicit structural definition to effectively generate fuzzing inputs.
Instead, Grimoire deduces the required input structure via feedback from the program.
Initial research suggests that this form of structure-inferring fuzz technique may be more effective than explicitly defined structured input fuzzing as Grimoire can probe corner cases which are excluded from formal grammars.

We propose extending the capabilities of Gramatron and Superion to support generating three structured inputs: YAML\cite{YAMLdraft}, JSON and Markdown.
We will compare the efficacy of our extended versions of Gramatron and Superion to both Grimoire and previous work targeted at fuzzing these three file formats.

Aside from the fact that there is room for these formats on extending our target fuzzers, we have numerous reasons for selecting YAML, JSON, and Markdown as our extension language.
First, it has a well-defined formal grammar, allowing it to be quickly and reliably integrated into the two fuzzers.
Second, these file formats are ubiquitous input formats.
This ubiquity makes our target languages a well-motivated language to extend these fuzzers to support.
Lastly, to a proper assessment of its performances, languages that have a sufficient corpus of CVEs are required. 
These languages have a decent amount CVEs that we can work with.
There are 108(YAML), 664(JSON), and 103(Markdown) CVEs on MITRE\cite{MITRE}.

The goal of this project is to extend the capabilities of both Gramatron and Superion, then compare their performance along with Grimoire towards replicated selected CVEs.
If the novel defect(s) are discovered and notable, we will consider the ancillary goal of publishing new CVE(s).

By utilizing the three fuzzers- Gramatron, Superion, and Grimoire- we hope to draw a rich comparison of modern fuzzing techniques.
After taking the cybersecurity course and learning about the fuzzing software, we hope to be well-equipped in determining whether these tools might be utilized as an automated method of finding software exploits in other domains.

Although we have confined our extension targets to two cutting-edge fuzzers for various reasons, 
there are other modern fuzzers that can be tackled in future projects such as; CodeAlchemist\cite{CodeAlchemist1}\cite{CodeAlchemist2}, Hawkeye\cite{Hawkeye}, Angora\cite{Angora1}\cite{Angora2}, CollAFL\cite{CollAFL}, IoTFuzzer\cite{IoTFuzzer}, RedQueen\,\cite{redqueen}, Nautilus\,\cite{Nautilus1}\cite{Nautilus2}, Periscope\cite{PeriScope1}\cite{PeriScope2}, T-Fuzz\,\cite{TFuzz1}\cite{TFuzz2}, Chopper\cite{Chopper}, QSYM\cite{QSYM1}\cite{QSYM2}, DigFuzz\cite{DigFuzz}, and FairFuzz\cite{FairFuzz1}\cite{FairFuzz2}.
All these tools are distinguished in their specialized scoped, but we have decided to work with Gramatron and Superion as these are open-sourced projects, and are specialized in generating structured inputs in a modular manner.

\vspace{3mm}
\section*{Approach}

We will extend the functionality of Gramatron to generate mutable, structure-aware YAML, JSON, and Markdown output.
Additionally, we will extend the functionality of Superion to generate mutable, structure-aware outputs in the same three target languages.
Both projects are open source and are modular in their design for incorporating new grammars.
These extensions, which are valuable to the wider fuzzing community, ought not to be too onerous.

Qualitatively, we will compose a corpus of CVEs discovered from previous work.
There are currently over 100 CVEs cataloged on MITRE\cite{MITRE} for each of our target languages.
We will select a reproducible subset of these CVEs to use as our coverage test.
The degree to which our extended fuzzing programs discover the known CVEs will be our qualitative metric of completeness.

\clearpage

Quantitatively, we will measure the execution time of each extended fuzzing program.
We will perform a comparison between Gramatron, Superion, and Grimoire mutation strategies in terms of how quickly they discover the known CVEs.
Where possible, we will also compare the performance of Gramatron, Superion, and Grimoire to previously published work which provides execution metrics.

We will generate a series of ``seed inputs'' for our three fuzzers which are accepted by the programs under test and generate expected behavior.
We will then allow these fuzzing programs to mutate the seed inputs\cite{Seed} according to their unique internal algorithms in order to probe for the CVE defects.
During the initial calibration of the fuzzers, we will manually monitor progress and adapt the seeds as needed to ensure that they are effectively probing the target programs.
Our programs under test will be those cataloged from the selected CVEs corpus.

The process of comparing these fuzzers opens the possibility of discovering novel defects outside the pre-selected CVEs.
While investigating these novel defects are outside the scope of this course project, we will take care to preserve the triggering inputs for future work.

The team expects to use their personal, commodity computer hardware to carry out this project.
However, should hardware constraints be discovered or it is determined to be beneficial for the project, the team members will have access to the DETER computing cluster at Hunter College.
Additionally, we can attempt to use Hunter's research credits on AWS.
Either way, we hope to reach a point of automation in the project where parallelization on a cluster is achievable, but can cope with commodity hardware.

Our project quantifying and qualifying the performance of these three modern fuzzers will lend valuable insight into the efficacy between these programs' internal algorithms, and how they compare to previous work.
This is of academic interest as it will inform the direction of future fuzzing research.


\vspace{4mm}
\section*{Findings}
\label{results}

\subsection*{Gramatron}

The fuzzing tool Gramatron was designed to produce structured fuzzing inputs for a defined grammar at extremely fast speed.
To achieve this, Gramatron constructs a grammar mutation deterministic finite automata (DFA).
Given a well-formed fuzzing input for the desired grammar, Gramatron uses the DFA to mutate the input into another well-formed input simply by move through transition sates of the DFA.
Given the compact and efficient nature of DFAs, each step through the transition space is constant time, and the resulting input mutation reduces to an informed string substitution.
This approach of iterative, sound mutations through a transition space is how Gramatron achieves it's exceptional speed while maintaining the desired structured fuzzing inputs.

However, this approach to fuzzing is not without it's limitations.
Because the mutation mechanism is a DFA, Grmatron can only produce coverage for grammars which are regular languages.
For any grammar which is more complex than a regular language, Gramatron can only produce a structured set of strings which represent a small sub-set of the entire grammar's set of acceptable strings.
This lack of expressiveness can leave large gaps in Gramatron's coverage.
For example, some recursive, or even context-free, production rules of a grammar will need to be modified or omitted for them to be convertible to a mutation DFA.
Since Gramatron's advertised usage is on context-sensitive and Turing-complete languages, careful inspection must be taken to understand what linguistic sacrifices were made and what subset of the language Gramatron produces coverage for.

The mechanism by which Gramatron takes a grammar specification and converts it into a DFA is through a pipeline of multiple grammar conversion.
First a grammar of production rules in either JSON or G4 format is converted to a new set of production rules Greibach Normal Form (GNF).
This conversion is not decidable.
Theoretically, if the largest production rule has $N$ non-terminals, then the GNF grammar can be represented by a push-down autamata (PDA) which, if it halts, will always halt with a stack depth of at most $N$.
However, if a GNF gramar has a recursive definition, it too is undecidable.
To be decidable, no non-terminal can transitively produce itself, i.e one must forbid productions of the (general) form $A \to B \to A$.
Once a the grammar is in GNF form, Gramatron \emph{assumes} that it is decidable and equivalent to the stack-limited, decidable PDA.
This assumption is not always sound.
Symbols are recursively substituted with their definitions.
After recursive substitution of depth $N$, all productions are in GNF form \emph{and} have at most one non-terminal per right-hand-side of a rule.
In this form, the grammar stack-limited PDA has had the potential state-space of the stack expanded out explicitly into a DFA.
This DFA is used as the mutator for Gramatron.

During our extension of Gramatron to support JSON and Markdown, we encountered numerous problems arising from the theoretical limitations above.
First, both JSON and Markdown are context free grammars with recursive definitions, and hence they cannot be directly converted to a DFA.
The conversion process from CFG to GNF for both grammars was fraught with infinite loops.
We dedicated substantial time to manually pre-defined both grammars in GNF to avoid the undecidability of general CFG to GNF conversion.
Subsequently, each grammar had to have it's transitive recursive form broken so that it could be converted into a DFA.
This process was also labor intensive as it require manual inspection of the grammars and elucidation as to which parts can be elided while still producing coverage for our selected CVEs.
Additionally, as part of Gramatron's internal conversion process from CFG to DFA, it disallows some characters which it considers to be special from existing within terminals and the label of non-terminals.
There is no escaping mechanism for these special characters provided by Gramatron.
One such character was the pipe (\texttt{'|'}) character, which is a required component of terminals in Markdown's definition of tables.
When special characters exist within the grammar definition, Gramatron does not provide any informative warning(s) to the user, rather it simply halts with a generic failure message.
Discovering the existence and circumvention of these special character took nearly a week of debugging Gramatron's source code.

Once Gramatron had successfully accepted our carefully tailored new grammar definitions and converted then to DFAs, we experienced a final and fatal complication.
Instead of producing structured output of either JSON or Markdown, instead Gramatron produced binary output of an indiscernible structure.
Each of the aforementioned complications depleted our available man-hours for this project and not enough time remained to begin again th arduous process of debugging Gramatron's source code.

The results of our attempted extension of Gramatron is the assessment that Gramatron manifests a powerful and novel technique in mutation-based, structure-aware fuzzing by utilizing tenets of formal language theory to convert a CFG structure to a DFA.
However, this assessment carries with it strong disclaimers.
Currently, Gramatron is in a prototype state and not amiable for general use. 
The engineering effort required to craft a new grammar for your specific fuzzing application is almost certainly greater than the effort require to use a less structured but more refined tool, such as AFL or AFL++.
We recommend monitoring the development and applications of Gramatron over the next few years to determine if the novel mutation-based technique it exemplifies is refined and expanded into a more usable construction or incorporated into other tools.

\subsection*{Selected CVEs}


For each target language, we’ve selected the target programs which have already contained multiple CVEs. There are certain criteria that we decide what target programs would be useful and efficient to get started with on fuzzing.  First, we’re looking for the open source code implemented by C or C++ as the target programs.  AFL works best on C or C++ applications. When source code is available, instrumentation can be injected by a companion tool that works as a drop-in replacement for gcc or clang in any standard build process for third-party code. For example, for C++ programs, we could set CXX=/path/to/afl/afl-g++ before we compile the code. Although AFL does support instrumenting black-box binaries on the fly with QEMU, but this tends to have poor performance. Second, we’ll need an executable or write a simple program that reads data from stdin or from a file to fuzz the target program. Lastly, the target program has some functions to deal with the target language. For example, one of our target programs is YAML-CPP which is a YAML parser and emitter in C++. Finally, we choose YAML-CPP as the YAML target and MD4C as the Markdown target.
The table below is a corpus of CVEs that we choose to run our tests on.

\begin{table}[h!]
\centering
\scalebox{0.8} {
\begin{tabular}{V{4}l|l|lV{4}} \hlineB{3}
	\multicolumn{1}{V{4}c|}{YAML} & \multicolumn{1}{c|}{JSON} & \multicolumn{1}{cV{4}}{Markdown}  \\ \hline
	\multicolumn{1}{V{4}c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2019-6292\cite{CVE-2021-42139}} \vspace{-2mm} \\ \footnotesize YAML-CPP < v0.6.2
	\end{tabular}} & 
	\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2019-6285\cite{CVE-2021-41106}} \vspace{-2mm} \\ \footnotesize JWT < v3.4.6
	\end{tabular}} &
	\multicolumn{1}{cV{4}}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-30027\cite{CVE-2021-30027}} \vspace{-2mm} \\ \footnotesize MD4C < 0.4.7 
	\end{tabular}} \\ \hline
	\multicolumn{1}{V{4}c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2019-6285\cite{CVE-2019-6285}} \vspace{-2mm} \\ \footnotesize YAML-CPP < v0.6.2
	\end{tabular}} & 
	\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-39215\cite{CVE-2021-39215}} \vspace{-2mm} \\ \footnotesize Jitsi Meet < v2.0.5963
	\end{tabular}} &
	\multicolumn{1}{cV{4}}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2020-26148\cite{CVE-2020-26148}} \vspace{-2mm} \\ \footnotesize MD4C < 0.4.5
	\end{tabular}} \\ \hline
	\multicolumn{1}{V{4}c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2018-20574\cite{CVE-2018-20574}} \vspace{-2mm} \\ \footnotesize YAML-CPP < v0.6.2
	\end{tabular}} & 
	\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-39205\cite{CVE-2021-39205}} \vspace{-2mm} \\ \footnotesize Jitsi Meet < v2.0.6173
	\end{tabular}} &
	\multicolumn{1}{cV{4}}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2018-12112\cite{CVE-2018-12112}} \vspace{-2mm} \\ \footnotesize MD4C < 0.2.6
	\end{tabular}} \\ \hline
	\multicolumn{1}{V{4}c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2018-20573\cite{CVE-2018-20573}} \vspace{-2mm} \\ \footnotesize YAML-CPP < v0.6.2 
	\end{tabular}} & 
	\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-32781\cite{CVE-2021-32781}} \vspace{-2mm} \\ \footnotesize Envoy < v1.16.5
	\end{tabular}} &
	\multicolumn{1}{cV{4}}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-37700\cite{CVE-2021-37700}} \vspace{-2mm} \\ \footnotesize @github/paste-markdown < v0.3.4
	\end{tabular}} \\ \hline
	\multicolumn{1}{V{4}c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2017-5950\cite{CVE-2017-5950}} \vspace{-2mm} \\ \footnotesize YAML-CPP < v0.5.3
	\end{tabular}} & 
	\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-32677\cite{CVE-2021-32677}} \vspace{-2mm} \\ \footnotesize FastAPI < v0.65.2
	\end{tabular}} &
	\multicolumn{1}{cV{4}}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-29503\cite{CVE-2021-29503}} \vspace{-2mm} \\ \footnotesize HedgeDoc < v1.8.2
	\end{tabular}} \\ \hline
	\multicolumn{1}{V{4}c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2017-11692\cite{CVE-2017-11692}} \vspace{-2mm} \\ \footnotesize YAML-CPP < v0.5.3
	\end{tabular}} & 
	\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-31618\cite{CVE-2021-31618}} \vspace{-2mm} \\ \footnotesize Apache HTTP Server mod\_http2 v1.15.17
	\end{tabular}} &
	\multicolumn{1}{cV{4}}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-29475\cite{CVE-2021-29475}} \vspace{-2mm} \\ \footnotesize HedgeDoc < v1.5.0
	\end{tabular}} \\ \hline
	\multicolumn{1}{V{4}c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-22557\cite{CVE-2021-22557}} \vspace{-2mm} \\ \footnotesize SLO generator < v2.0.0
	\end{tabular}} & 
	\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-30641\cite{CVE-2021-30641}} \vspace{-2mm} \\ \footnotesize Apache HTTP Server v2.4.39-v2.4.46
	\end{tabular}} &
	\multicolumn{1}{cV{4}}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-29474\cite{CVE-2021-29474}} \vspace{-2mm} \\ \footnotesize HedgeDoc < v1.8.0
	\end{tabular}} \\ \hline
	\multicolumn{1}{V{4}c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-21250\cite{CVE-2021-21250}} \vspace{-2mm} \\ \footnotesize OneDev < v4.0.3
	\end{tabular}} & 
	\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-30179\cite{CVE-2021-30179}} \vspace{-2mm} \\ \footnotesize Apache Dubbo < v2.6.9
	\end{tabular}} &
	\multicolumn{1}{cV{4}}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-27907\cite{CVE-2021-27907}} \vspace{-2mm} \\ \footnotesize Apache Superset $\leq$ v0.38.0
	\end{tabular}} \\ \hline
	\multicolumn{1}{V{4}c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-21249\cite{CVE-2021-21249}} \vspace{-2mm} \\ \footnotesize OneDev < v4.0.3
	\end{tabular}} & 
	\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-26691\cite{CVE-2021-26691}} \vspace{-2mm} \\ \footnotesize Apache HTTP Server v2.4.0-v2.4.46
	\end{tabular}} &
	\multicolumn{1}{cV{4}}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-27578\cite{CVE-2021-27578}} \vspace{-2mm} \\ \footnotesize Apache Zeppelin < v0.9.0
	\end{tabular}} \\ \hline
	\multicolumn{1}{V{4}c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2020-7729\cite{CVE-2020-7729}} \vspace{-2mm} \\ \footnotesize Grunt < v1.3.0
	\end{tabular}} & 
	\multicolumn{1}{c|}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-26690\cite{CVE-2021-26690}} \vspace{-2mm} \\ \footnotesize Apache HTTP Server v2.4.0-v2.4.46
	\end{tabular}} & 
	\multicolumn{1}{cV{4}}{\begin{tabular}[c]{@{}c@{}}
		\texttt{CVE-2021-22242\cite{CVE-2021-22242}} \vspace{-2mm} \\ \footnotesize GitLab CE/EE > v11.4
	\end{tabular}} \\ \hlineB{3}
\end{tabular}
}
\vspace{6mm}\\ \textbf{Table 1.} Target CVEs for each languages
\end{table}
\vspace{6mm}

Selected CVEs and the defective applications are shown at the bottom of each cell of \textbf{Table 1}. The numbers next to the name indicate the latest version that the defect was fixed. For example, CVE-2021-42139 can be found in the Deno version prior to 0.107.0.


We have administered two major tasks prior to extending the functionality of each fuzzers.
First, we have set up Gramatron and Superion to run in the test environment.
The input generators for each fuzzer successfully constructed seed files \cite{superion-example}\cite{gramatron-example}that conform to the grammatic constraints of Javascript.
Configuring grammar-specific protocols and rules for extending each fuzzer was followed by the environment setup.
This was done through the course of literature review and presentation preparation, and we have built the JSON grammar definition\cite{json-source.json} for extending Gramatron.

\vspace{12mm}
\hrule height 0.4mm
\begingroup \fontsize{12pt}{12pt} \selectfont \begin{alltt}
\input{input.js}
\end{alltt} \vspace{-6mm} \endgroup \hrule height 0.4mm
\vspace{6mm}
\centerline{\textbf{Figure 3.} Input created from Grammar-aware input generators}
\vspace{6mm}


\section*{Discussion}

Based on the fuzzing tests conducted on the selected CVEs, we found that our extension of Superion and Gramatron were feasible. 

Superion generated an input that resembled human-written javascript, by taking a context free grammar and an input seed,
then performing a series of "grammar-aware" mutations to create a sequence of validly structured inputs.
Superion created an input that was similar to what we were looking for. 

Meanwhile, Gramatron was harder to read.
This may be because Gramatron reduces the number of mutation steps from the input seed to the trigger input. 

We hope to show that our tests on the extensions of Superion and Gramatron will be more performant than those conducted on Grimoire since Superion and Gramatron directly produce the inputs,
while Grimoire creates the input from feedback, rather than a defined structure.

\section*{Future Experimentation}
For the future work, Grimoire, Gramatron, Superion could be combined for large-scale testing to explore the new CVEs. 
We can combine the structured inputs generated from Gramatron, Superion with Grimoire, since Grimoire generates input only based on the feedback.
Lastly, we can keep extending the fuzzers to support more languages for generating the grammar aware inputs.


\clearpage

\section*{Division of Labor}

Alex Washburn devised the main concept of the project.
Alex Washburn and Chuanyao Lin designed the project and derive fuzzing techniques.
Sabina Bhuiyan and Kyoungwoo Lee conducted literature reviews and related research on extending the fuzzing tools.
Chuanyao Lin and Kyoungwoo Lee extended Gramatron to support targeted file formats.
Alex Washburn and Sabina Bhuiyan extended Superion to support targeted languages.
Kyoungwoo Lee and Alex Washburn configured the fuzzing environment on AWS/DETER.
Each member conducted fuzzing on the divided set of CVEs.
Chuanyao Lin and Sabina Bhuiyan analyzed the project in comparison with Grimoire and authored the reports.


\section*{Timeline}

The project timeline is partially defined by the course syllabus where deadlines are concerned
and partially team defined where the syllabus does not give guidance.
The team has collaboratively discussed and drafted a tentative timeline of the project based on our assumptions of progress and integrated this with the deliverable deadlines laid out in the course syllabus. The current, tentative project timeline is as follows:

\begin{enumerate}[label={}]
	\item \texttt{2021-08-29:} Form team and brainstorm project ideas
	\item \texttt{2021-09-05:} \textbf{Project Proposal due}
	\item \texttt{2021-09-12:} Revise and resubmit proposal
	\item \texttt{2021-09-19:} Background research \& revise \/ resubmit proposal
	\item \texttt{2021-09-26:} Background research \& revise \/ resubmit proposal
	\item \texttt{2021-10-03:} Finalize proposal, Collect and finalize CVEs corpus
	\item \texttt{2021-10-10:} \textbf{Midterm project presentations due}
	\item \texttt{2021-10-17:} \textbf{Midterm project reports due} \hfill (Tune fuzzing instrumentation)
	\item \texttt{2021-10-24:} Begin modifying Superion \& Gramatron
	\item \texttt{2021-10-31:} Complete modified Gramatron \& Superion generating
	\item \texttt{2021-11-07:} Tune 3 fuzzers instrumentation with programs under test
	\item \texttt{2021-11-14:} Replicate CVEs and document performance
	\item \texttt{2021-11-21:} Parallelize fuzzing \hfill (DETER/AWS)
	\item \texttt{2021-11-28:} Finish replication of CVEs and document
	\item \texttt{2021-12-05:} \textbf{Final project presentations due}
	\item \texttt{2021-12-12:} \textbf{Final project reports due 5:35 pm}
\end{enumerate}


\clearpage

\bibliographystyle{acm}
\bibliography{final-report}

\end{document}
